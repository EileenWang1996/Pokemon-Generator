# -*- coding: utf-8 -*-
"""pokegan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13Ac2JrlZx4yZS2U4xygSk3FrPXAgunGy
"""

import os 
import tensorflow as tf 
import scipy.misc 
import numpy as np 
import cv2
from tensorflow.contrib import layers
import matplotlib.pyplot as plt
from random import randint

#initialising some constants 
HEIGHT, WIDTH, CHANNEL = 128, 128, 3
BATCH_SIZE = 64
EPOCH = 2000
poke_path = "./generated_pokemon" #where the generated images will be saved
checkpoint_save_path = "./model/generated_pokemon"
random_dimension = 100
training = [] #stores the name of each image as a string 
gloss = []
dloss = []

def create_vid(image_folder, video_name): 
    '''Create a video from the generated images'''
    images = []
    for i in range(0, EPOCH, 10): 
        image = cv2.imread(poke_path + "/epoch%d.jpg" % i)
        if image is not None: 
            images.append(image)
    height, width, layers = images[0].shape
    video = cv2.VideoWriter(video_name, -1, 1, (width,height))

    for img in images:
        video.write(img)

    cv2.destroyAllWindows()
    video.release()

def leaky_relu(x): 
    '''Helper function for leaky relu'''
    return tf.maximum(x, 0.2 * x)

def get_training_data(): 
    '''Get the names of training data files.'''
    filedir = os.listdir() 
    for img in filedir: 
      if img.endswith(".jpg"):
        training.append(img)

def combine_images(generated_images): 
    '''Combine images into one big 8 x 8 image.'''
    columns = []
    for i in range(0, 64, 8): 
        col = np.concatenate((generated_images[i], generated_images[i+1], generated_images[i+2], generated_images[i+3], 
                            generated_images[i+4], generated_images[i+5], generated_images[i+6], generated_images[i+7]), axis = 0) 
        columns.append(col)
    final_img = np.concatenate((columns[0], columns[1], columns[2], columns[3], columns[4], columns[5],
                              columns[6], columns[7]), axis = 1)
    final_img = (final_img + 1)*255/2 #convert float32 image to uint8 image
    return final_img

def augment_images(image_names):
  '''Apply data augmentation techniques on the batch of images.'''
  
  batch = []
  for i in range(0, image_names.shape[0]): #loop through each randomly selected image
    image_content = tf.read_file(image_names[i])
    decoded_img = tf.image.decode_jpeg(image_content, channels = CHANNEL)
    
    #Apply data augmentation to each image in the batch 
    img = tf.image.random_flip_left_right(decoded_img) #flip horizontally 
    img = tf.image.random_flip_up_down(img) #flip vertically 
    img = tf.image.random_saturation(img, lower = 0.8, upper = 1.4)
    img = tf.image.random_brightness(img, max_delta = 0.4)
    img = tf.image.random_contrast(img, lower = 0.8, upper = 1.4)
    img = tf.image.rot90(img, k = randint(0,3)) #randomly rotate the image 
    
    random_int1 = randint(0,3) #1 in 4 chance that we will crop the image 
    if random_int1 == 0:   
      img = tf.image.central_crop(img, np.random.uniform(0.5, 1)) 
      img = tf.image.resize_image_with_crop_or_pad(img, HEIGHT, WIDTH) #pad the cropped image 
    
    random_int2 = randint(0,3) #1 in 4 chance that we will transpose it 
    if random_int2 == 0: 
      img = tf.image.transpose_image(img)
     
    img = tf.image.resize_images(decoded_img, [HEIGHT, WIDTH])
    img.set_shape([HEIGHT, WIDTH, CHANNEL])
    img = tf.cast(img, tf.float32) #convert uint8 image to float32
    img = img/255 #normalise the values to be between 0 and 1
    batch.append(img)
    
  return batch

def get_batch(): 
  '''Returns a random batch of 64 images.'''
  
  #first get a random batch 
  random_indices = np.arange(0, len(training))
  np.random.shuffle(random_indices)
  random_indices = random_indices[0:BATCH_SIZE]
  batch_names = [training[i] for i in random_indices] 
  
  image_names = tf.convert_to_tensor(batch_names, dtype = tf.string) #convert each name of image to a string tensor; a tensor list
  batch = augment_images(image_names)
  batch = tf.stack(batch) #this will have shape (64, 128, 128, 3)

  return batch

def generator(random_input): #deconvolutional network
    '''Generator tries to generate some fake pokemon.'''
    with tf.variable_scope("generator"): 
        #start with the fully connected layor 
        gen_weight = tf.get_variable(name = "gen_weight",shape = [random_dimension, 8 * 8 * 512], dtype = tf.float32, initializer = tf.truncated_normal_initializer(stddev=0.02)) 
        gen_bias = tf.get_variable(name = "gen_bias", shape = [8 * 8 * 512], dtype = tf.float32, initializer = tf.constant_initializer(0.0))
        convolution1 = tf.add(tf.matmul(random_input, gen_weight), gen_bias) #result: batch_size * (8 * 8 * 512)
        convolution1 = tf.reshape(convolution1, shape = [-1, 8, 8, 512], name = "convolution1")
        batch_norm1 = layers.batch_norm(convolution1,  epsilon = 1e-5, scope = "norm1")
        activation1 = tf.nn.relu(batch_norm1)
        
        #convolution layer 2 
        convolution2 = tf.layers.conv2d_transpose(activation1, filters = 256, kernel_size = 5, strides = 2, padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))
        batch_norm2 = layers.batch_norm(convolution2, epsilon = 1e-5, scope = "norm2")
        activation2 = tf.nn.relu(batch_norm2)
       
        #convolution layer 3 
        convolution3 = tf.layers.conv2d_transpose(activation2, filters = 128, kernel_size = 5, strides = 2, padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))
        batch_norm3 = layers.batch_norm(convolution3, epsilon = 1e-5, scope = "norm3")
        activation3 = tf.nn.relu(batch_norm3) 
        
        #convolution layer 4
        convolution4 = tf.layers.conv2d_transpose(activation3, filters = 64, kernel_size = 5, strides = 2, padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))
        batch_norm4 = layers.batch_norm(convolution4, epsilon = 1e-5, scope = "norm4")
        activation4 = tf.nn.relu(batch_norm4) 
        
        #convolution layer 5
        convolution5 = tf.layers.conv2d_transpose(activation4, filters = 32, kernel_size = 5, strides = 2, padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))
        batch_norm5 = layers.batch_norm(convolution4, epsilon = 1e-5, scope = "norm5")
        activation5 = tf.nn.relu(batch_norm4) 
       
        #convolution layer 6
        convolution6 = tf.layers.conv2d_transpose(activation5, filters = CHANNEL, kernel_size = 5, strides = 2, padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))
        activation6 = tf.nn.tanh(convolution6) 
        #print(activation6.shape)
        return activation6

def discriminator(input, reuse): 
    '''Discriminator tries to find the fake images that generator generates.'''
    with tf.variable_scope("discriminator", reuse = reuse): 
        #convolution layer 1 
        convolution1 = tf.layers.conv2d(input, filters = 64, kernel_size = 5, strides = 2, padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))
        batch_norm1 = layers.batch_norm(convolution1, epsilon = 1e-5, scope = "norm1")
        activation1 = leaky_relu(convolution1)
        
        #convolution layer 2
        convolution2 = tf.layers.conv2d(activation1, filters = 128, kernel_size = 5, strides = 2, padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))
        batch_norm2 = layers.batch_norm(convolution2, epsilon = 1e-5, scope = "norm2")
        activation2 = leaky_relu(batch_norm2)
        
        #convolution layer 3
        convolution3 = tf.layers.conv2d(activation2, filters = 256, kernel_size = 5, strides = 2, padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))
        batch_norm3 = layers.batch_norm(convolution3, epsilon = 1e-5, scope = "norm3")
        activation3 = leaky_relu(batch_norm3)
        
        #convolution layer 4
        convolution4 = tf.layers.conv2d(activation3, filters = 512, kernel_size = 5, strides = 2, padding = "SAME", kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))
        batch_norm4 = layers.batch_norm(convolution4, epsilon = 1e-5, scope = "norm4")
        activation4 = leaky_relu(batch_norm4)
        
        #fully connected layer 
        activation4_dim = int(np.prod(activation4.get_shape()[1:])) #get the dimensions of the 4th activation 
        activation4_flat = tf.reshape(activation4, shape = [-1, activation4_dim]) #flatten it 
        disc_weight = tf.get_variable(name = "disc_weight", shape = [activation4_flat.shape[-1], 1], dtype = tf.float32, 
                                      initializer = tf.truncated_normal_initializer(stddev=0.02))
        disc_bias = tf.get_variable(name = "disc_bias", shape = [1], dtype = tf.float32, initializer = tf.constant_initializer(0.0))
        logits = tf.add(tf.matmul(activation4_flat, disc_weight), disc_bias, name = "logits")
        return logits

'''Create tensor graph variables.'''
tf.reset_default_graph() #reset graph
with(tf.name_scope("placeholders")): 
  real_pokemon = tf.placeholder(tf.float32, shape = [None, HEIGHT, WIDTH, CHANNEL], name = "real_pokemon")
  random_input = tf.placeholder(tf.float32, shape = [None, random_dimension], name = "random_input") #random input to feed in generator
    
  fake_pokemon = generator(random_input) #generator generates some fake pokemon with noisy data 
  real_pokemon_result = discriminator(real_pokemon, reuse = False)
  fake_pokemon_result = discriminator(fake_pokemon, reuse = True) #discriminator training on fake pokemon images
        
with tf.name_scope("loss"): 
  discriminator_loss = tf.reduce_mean(fake_pokemon_result) - tf.reduce_mean(real_pokemon_result)
  generator_loss = -tf.reduce_mean(fake_pokemon_result)

with tf.name_scope("optimiser"): 
  generator_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = "generator")
  discriminator_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = "discriminator")
  generator_train = tf.train.RMSPropOptimizer(learning_rate = 2e-4).minimize(generator_loss, var_list = generator_vars)
  discriminator_train = tf.train.RMSPropOptimizer(learning_rate = 2e-4).minimize(discriminator_loss, var_list = discriminator_vars)
  clip_discriminator = [d.assign(tf.clip_by_value(d, -0.01, 0.01)) for d in discriminator_vars]

def train():
    '''Open sessions and restore'''
    sess = tf.Session()
    sess.run(tf.global_variables_initializer()) #initialise global and local variables 
    sess.run(tf.local_variables_initializer())

    saver = tf.train.Saver() #save and restore variables 
    save_path = saver.save(sess, "/tmp/model.ckpt") #save path of our model 
    checkpoint = tf.train.latest_checkpoint(os.getcwd())
    saver.restore(sess, checkpoint)
    
    '''Initiate training loop!'''
    random_batch = get_batch()
    batch_num = int(len(training)/BATCH_SIZE)
    for i in range(0,EPOCH):
        print("RUNNING EPOCH: ", i)
        
        for j in range(batch_num):
            random_noise = np.random.uniform(-1.0, 1.0, size=[BATCH_SIZE, random_dimension]).astype(np.float32)
            for k in range(5):
                training_batch = sess.run(random_batch)
                _, d_loss, _ = sess.run([discriminator_train, discriminator_loss, clip_discriminator],
                                    feed_dict={random_input: random_noise, real_pokemon: training_batch})
                if k == 4: 
                  dloss.append(d_loss)
            # Update the generator
            _, g_loss = sess.run([generator_train, generator_loss], feed_dict={random_input: random_noise})
            gloss.append(g_loss)
        if i % 100 == 0: #save check point every 500 epoch
            if not os.path.exists(checkpoint_save_path):
                os.makedirs(checkpoint_save_path)
            saver.save(sess, checkpoint_save_path + str(i))  
        
        if i % 10 == 0: # save generator images every 10 epoch
            if not os.path.exists(poke_path):
                os.makedirs(poke_path)
            random_noise = np.random.uniform(-1.0, 1.0, size=[BATCH_SIZE, random_dimension]).astype(np.float32)
            generated_images = sess.run(fake_pokemon, feed_dict={random_input: random_noise})
            generated_images = combine_images(generated_images)
            scipy.misc.imsave(poke_path + '/epoch' + str(i) + '.jpg', generated_images)
            print("DISCRIMINATOR LOSS: ", d_loss, " GENERATOR LOSS: ", g_loss)

if __name__ == "__main__":
    get_training_data()
    train()